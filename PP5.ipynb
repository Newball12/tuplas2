{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Newball12/tuplas2/blob/main/PP5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# Descargue los recursos NLTK necesarios\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Cargar los datos usando Dask\n",
        "df = dd.read_csv('tweets_dataset.csv')\n",
        "\n",
        "# Función para limpiar y tokenizar un tweet\n",
        "def limpiar_tokenizar(texto):\n",
        "    # Tokenización\n",
        "    tokens = word_tokenize(texto)\n",
        "    # Convertir a minúsculas, eliminar palabras vacías, puntuación y números\n",
        "    stop_words = set(stopwords.words('spanish'))\n",
        "    tokens = [token.lower() for token in tokens if token not in stop_words and token not in string.punctuation and not token.isdigit()]\n",
        "    return tokens\n",
        "\n",
        "# Función para analizar el sentimiento.\n",
        "def analizar_sentimiento(texto):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    sentiment = sia.polarity_scores(texto)\n",
        "    return sentiment['compound']\n",
        "\n",
        "# Aplicar la función de limpieza y tokenización.\n",
        "df['tokens'] = df[\"texto\"].apply(limpiar_tokenizar, meta=('tokens', 'object'))\n",
        "\n",
        "# Crea una nueva columna con los tokens unidos por espacios\n",
        "df['texto_limpio'] = df['tokens'].apply(lambda x: ' '.join(x), meta=('texto_limpio', 'object'))\n",
        "\n",
        "# Aplicar la función de análisis de sentimiento.\n",
        "df['sentimiento'] = df['texto_limpio'].apply(analizar_sentimiento, meta=('sentimiento', 'float64'))\n",
        "\n",
        "# Clasificar los sentimientos\n",
        "df['polaridad'] = df['sentimiento'].apply(lambda x: 'positivo' if x > 0.05 else ('negativo' if x < -0.05 else 'neutral'), meta=('polaridad', 'object'))\n",
        "\n",
        "# Calcular y cronometrar la ejecución de Dask\n",
        "import time\n",
        "start_time = time.time()\n",
        "computed_df = df.compute()  # Cálculo de activación para Dask\n",
        "end_time = time.time()\n",
        "dask_execution_time = end_time - start_time\n",
        "print(f\"Dask execution time: {dask_execution_time} seconds\")\n",
        "\n",
        "# Mostrar los primeros 5 resultados\n",
        "print(computed_df.head())\n",
        "\n",
        "# Crear un DataFrame con los resultados del análisis de sentimiento\n",
        "resultados_sentimiento = computed_df['polaridad'].value_counts().reset_index()\n",
        "resultados_sentimiento.columns = ['Polaridad_sentimientos', 'Conteo']\n",
        "\n",
        "# Calcular porcentajes y agregarlos al DataFrame\n",
        "resultados_sentimiento['Porcentaje'] = (resultados_sentimiento['Conteo'] / resultados_sentimiento['Conteo'].sum()) * 100\n",
        "resultados_sentimiento['Porcentaje'] = resultados_sentimiento['Porcentaje'].map('{:.2f}%'.format)\n",
        "\n",
        "# Mostrar la tabla\n",
        "print(resultados_sentimiento)\n",
        "\n",
        "# Ahora, cronometremos la ejecución para un procesamiento de un solo nodo usando pandas.\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar los datos usando pandas\n",
        "df_pandas = pd.read_csv('tweets_dataset.csv')\n",
        "\n",
        "start_time = time.time()\n",
        "# Aplicar las funciones al DataFrame de pandas (igual que antes)\n",
        "df_pandas['tokens'] = df_pandas[\"texto\"].apply(limpiar_tokenizar)\n",
        "df_pandas['texto_limpio'] = df_pandas['tokens'].apply(lambda x: ' '.join(x))\n",
        "df_pandas['sentimiento'] = df_pandas['texto_limpio'].apply(analizar_sentimiento)\n",
        "df_pandas['polaridad'] = df_pandas['sentimiento'].apply(lambda x: 'positivo' if x > 0.05 else ('negativo' if x < -0.05 else 'neutral'))\n",
        "end_time = time.time()\n",
        "pandas_execution_time = end_time - start_time\n",
        "print(f\"Pandas execution time: {pandas_execution_time} seconds\")\n",
        "\n",
        "print(f\"Speedup with Dask: {pandas_execution_time / dask_execution_time:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7X41ON8b_oa",
        "outputId": "0683a772-5a82-4d27-f292-0c1fa58e47f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dask execution time: 3.586512804031372 seconds\n",
            "   id                                              texto                fecha  \\\n",
            "0   1       ¡Me encanta el nuevo producto! Es increíble.  2023-12-05 11:58:00   \n",
            "1   2  El producto no funciona como esperaba. Muy dec...  2023-12-19 21:44:00   \n",
            "2   3  El servicio al cliente fue pésimo, no volveré ...  2023-12-29 11:56:00   \n",
            "3   4  ¡Es un excelente producto, lo recomiendo total...  2023-12-04 11:53:00   \n",
            "4   5    Podría ser mejor, pero en general es aceptable.  2023-11-06 10:18:00   \n",
            "\n",
            "                                              tokens  \\\n",
            "0  ['¡me', 'encanta', 'nuevo', 'producto', 'es', ...   \n",
            "1  ['el', 'producto', 'funciona', 'esperaba', 'mu...   \n",
            "2  ['el', 'servicio', 'cliente', 'pésimo', 'volve...   \n",
            "3  ['¡es', 'excelente', 'producto', 'recomiendo',...   \n",
            "4  ['podría', 'ser', 'mejor', 'general', 'aceptab...   \n",
            "\n",
            "                                        texto_limpio  sentimiento polaridad  \n",
            "0  [ ' ¡ m e ' ,   ' e n c a n t a ' ,   ' n u e ...          0.0   neutral  \n",
            "1  [ ' e l ' ,   ' p r o d u c t o ' ,   ' f u n ...          0.0   neutral  \n",
            "2  [ ' e l ' ,   ' s e r v i c i o ' ,   ' c l i ...          0.0   neutral  \n",
            "3  [ ' ¡ e s ' ,   ' e x c e l e n t e ' ,   ' p ...          0.0   neutral  \n",
            "4  [ ' p o d r í a ' ,   ' s e r ' ,   ' m e j o ...          0.0   neutral  \n",
            "  Polaridad_sentimientos  Conteo Porcentaje\n",
            "0                neutral     500    100.00%\n",
            "Pandas execution time: 3.684633255004883 seconds\n",
            "Speedup with Dask: 1.03x\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Te damos la bienvenida a Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}