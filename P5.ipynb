{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Newball12/tuplas2/blob/main/P5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load the data using Dask\n",
        "df = dd.read_csv('tweets_dataset.csv')\n",
        "\n",
        "# Function to clean and tokenize a tweet\n",
        "def limpiar_tokenizar(texto):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(texto)\n",
        "    # Convert to lowercase, remove stop words, punctuation and numbers\n",
        "    stop_words = set(stopwords.words('spanish'))\n",
        "    tokens = [token.lower() for token in tokens if token not in stop_words and token not in string.punctuation and not token.isdigit()]\n",
        "    return tokens\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def analizar_sentimiento(texto):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    sentiment = sia.polarity_scores(texto)\n",
        "    return sentiment['compound']\n",
        "\n",
        "# Apply the cleaning and tokenization function\n",
        "df['tokens'] = df[\"texto\"].apply(limpiar_tokenizar, meta=('tokens', 'object'))\n",
        "\n",
        "# Create a new column with the tokens joined by spaces\n",
        "df['texto_limpio'] = df['tokens'].apply(lambda x: ' '.join(x), meta=('texto_limpio', 'object'))\n",
        "\n",
        "# Apply the sentiment analysis function\n",
        "df['sentimiento'] = df['texto_limpio'].apply(analizar_sentimiento, meta=('sentimiento', 'float64'))\n",
        "\n",
        "# Classify the sentiments\n",
        "df['polaridad'] = df['sentimiento'].apply(lambda x: 'positivo' if x > 0.05 else ('negativo' if x < -0.05 else 'neutral'), meta=('polaridad', 'object'))\n",
        "\n",
        "# Compute and time the execution for Dask\n",
        "import time\n",
        "start_time = time.time()\n",
        "computed_df = df.compute()  # Trigger computation for Dask\n",
        "end_time = time.time()\n",
        "dask_execution_time = end_time - start_time\n",
        "print(f\"Dask execution time: {dask_execution_time} seconds\")\n",
        "\n",
        "# Display the first 5 results\n",
        "print(computed_df.head())\n",
        "\n",
        "# Create a DataFrame with the results of the sentiment analysis\n",
        "resultados_sentimiento = computed_df['polaridad'].value_counts().reset_index()\n",
        "resultados_sentimiento.columns = ['Polaridad_sentimientos', 'Conteo']\n",
        "\n",
        "# Calculate percentages and add them to the DataFrame\n",
        "resultados_sentimiento['Porcentaje'] = (resultados_sentimiento['Conteo'] / resultados_sentimiento['Conteo'].sum()) * 100\n",
        "resultados_sentimiento['Porcentaje'] = resultados_sentimiento['Porcentaje'].map('{:.2f}%'.format)\n",
        "\n",
        "# Display the table\n",
        "print(resultados_sentimiento)\n",
        "\n",
        "# Now, let's time the execution for a single-node processing using pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data using pandas\n",
        "df_pandas = pd.read_csv('tweets_dataset.csv')\n",
        "\n",
        "start_time = time.time()\n",
        "# Apply the functions to the pandas DataFrame (same as before)\n",
        "df_pandas['tokens'] = df_pandas[\"texto\"].apply(limpiar_tokenizar)\n",
        "df_pandas['texto_limpio'] = df_pandas['tokens'].apply(lambda x: ' '.join(x))\n",
        "df_pandas['sentimiento'] = df_pandas['texto_limpio'].apply(analizar_sentimiento)\n",
        "df_pandas['polaridad'] = df_pandas['sentimiento'].apply(lambda x: 'positivo' if x > 0.05 else ('negativo' if x < -0.05 else 'neutral'))\n",
        "end_time = time.time()\n",
        "pandas_execution_time = end_time - start_time\n",
        "print(f\"Pandas execution time: {pandas_execution_time} seconds\")\n",
        "\n",
        "print(f\"Speedup with Dask: {pandas_execution_time / dask_execution_time:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7X41ON8b_oa",
        "outputId": "bc9ad892-bcce-44c8-97e9-3f0e56d87cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dask execution time: 7.3397886753082275 seconds\n",
            "   id                                              texto                fecha  \\\n",
            "0   1       ¡Me encanta el nuevo producto! Es increíble.  2023-12-05 11:58:00   \n",
            "1   2  El producto no funciona como esperaba. Muy dec...  2023-12-19 21:44:00   \n",
            "2   3  El servicio al cliente fue pésimo, no volveré ...  2023-12-29 11:56:00   \n",
            "3   4  ¡Es un excelente producto, lo recomiendo total...  2023-12-04 11:53:00   \n",
            "4   5    Podría ser mejor, pero en general es aceptable.  2023-11-06 10:18:00   \n",
            "\n",
            "                                              tokens  \\\n",
            "0  ['¡me', 'encanta', 'nuevo', 'producto', 'es', ...   \n",
            "1  ['el', 'producto', 'funciona', 'esperaba', 'mu...   \n",
            "2  ['el', 'servicio', 'cliente', 'pésimo', 'volve...   \n",
            "3  ['¡es', 'excelente', 'producto', 'recomiendo',...   \n",
            "4  ['podría', 'ser', 'mejor', 'general', 'aceptab...   \n",
            "\n",
            "                                        texto_limpio  sentimiento polaridad  \n",
            "0  [ ' ¡ m e ' ,   ' e n c a n t a ' ,   ' n u e ...          0.0   neutral  \n",
            "1  [ ' e l ' ,   ' p r o d u c t o ' ,   ' f u n ...          0.0   neutral  \n",
            "2  [ ' e l ' ,   ' s e r v i c i o ' ,   ' c l i ...          0.0   neutral  \n",
            "3  [ ' ¡ e s ' ,   ' e x c e l e n t e ' ,   ' p ...          0.0   neutral  \n",
            "4  [ ' p o d r í a ' ,   ' s e r ' ,   ' m e j o ...          0.0   neutral  \n",
            "  Polaridad_sentimientos  Conteo Porcentaje\n",
            "0                neutral     500    100.00%\n",
            "Pandas execution time: 3.700892686843872 seconds\n",
            "Speedup with Dask: 0.50x\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Te damos la bienvenida a Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}